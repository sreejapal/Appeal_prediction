{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbe58d2-53ff-4d7a-b2d9-0dd65bb0c3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: filelock in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: networkx in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from requests->transformers) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: fsspec in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --progress-bar on transformers accelerate sentencepiece\n",
    "!pip install --progress-bar on pandas numpy matplotlib\n",
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124 -v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7681fc0-7fb7-45bc-9722-026dbd43e7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "355e8caa-5f6c-410a-ae94-c9dfb333f486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "Torch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc82f778-ca28-484b-bc42-dff38004c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.3.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: stack_data in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: decorator in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: wcwidth in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: pure-eval in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03998858-a7e3-4b90-a040-09a2849d4c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "675a1bd4-e7f5-4e27-88c7-060af2d86e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7120cf-aaa3-4d20-88bd-407f2920402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"CJPE_ext_SCI_HCs_Tribunals_daily_orders_single.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a22dba4-216a-4a60-b8fb-ac66755e2e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calcutta_High_Court_Appellete_Side_2008_2020_2...</td>\n",
       "      <td>Judgment on 18th April, 2008.Bhaskar J.These t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bombay_HC_BomHC_1937_179</td>\n",
       "      <td>Beaumont, C.J.This is an appeal from a decisio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>karnataka_HC_1998_425</td>\n",
       "      <td>The appellant has filed this appeal assailing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bombay_HC_BomHC_1994_60</td>\n",
       "      <td>The petitioner, Forbes Forbes Campbel and.Comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madras_HC_2017_4649</td>\n",
       "      <td>The writ petitioner was allotted plot No.60 fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  Calcutta_High_Court_Appellete_Side_2008_2020_2...   \n",
       "1                           Bombay_HC_BomHC_1937_179   \n",
       "2                              karnataka_HC_1998_425   \n",
       "3                            Bombay_HC_BomHC_1994_60   \n",
       "4                                Madras_HC_2017_4649   \n",
       "\n",
       "                                                text  label  \n",
       "0  Judgment on 18th April, 2008.Bhaskar J.These t...      0  \n",
       "1  Beaumont, C.J.This is an appeal from a decisio...      0  \n",
       "2  The appellant has filed this appeal assailing ...      0  \n",
       "3  The petitioner, Forbes Forbes Campbel and.Comp...      1  \n",
       "4  The writ petitioner was allotted plot No.60 fo...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f34842f-0483-486e-b6f9-d597647e0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=pd.read_csv(\"CJPE_ext_SCI_HCs_Tribunals_daily_orders_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d520b21-36fb-4506-8351-319edeee5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"CJPE_ext_SCI_HCs_Tribunals_daily_orders_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dccd33a-25f8-49aa-9d2a-689a3d7a6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.drop(columns=[\"filename\"],inplace=True)\n",
    "test.drop(columns=[\"filename\"],inplace=True)\n",
    "train.drop(columns=[\"filename\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9c129af-56c5-48d4-bec6-6d6c2c146d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The plaintiffs are the appellants against the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Judgment of the Court was made by The present...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. E.I.Sanmathi, Adv.for Ms. Vani H, Adv.for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Govindasamy J. Lakshmi Vilas Bank, the first r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 1st petitioner was an LPG distributor at K...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  The plaintiffs are the appellants against the ...      1\n",
       "1  (Judgment of the Court was made by The present...      0\n",
       "2  Mr. E.I.Sanmathi, Adv.for Ms. Vani H, Adv.for ...      0\n",
       "3  Govindasamy J. Lakshmi Vilas Bank, the first r...      0\n",
       "4  The 1st petitioner was an LPG distributor at K...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97307c68-f8c8-40a9-bf4b-048226ec11d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judgment on 18th April, 2008.Bhaskar J.These t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beaumont, C.J.This is an appeal from a decisio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The appellant has filed this appeal assailing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The petitioner, Forbes Forbes Campbel and.Comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The writ petitioner was allotted plot No.60 fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Judgment on 18th April, 2008.Bhaskar J.These t...      0\n",
       "1  Beaumont, C.J.This is an appeal from a decisio...      0\n",
       "2  The appellant has filed this appeal assailing ...      0\n",
       "3  The petitioner, Forbes Forbes Campbel and.Comp...      1\n",
       "4  The writ petitioner was allotted plot No.60 fo...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3590b59-cc51-4e59-9246-93545c7a8332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ratio Held Legal documents amend in the above ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counsel for Respondent - Ojha Honble Dr. Yeshw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charge sheet has been filed in the present cas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coram Honble Ramesh C.J.Honble Alok Kumar Verm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The has this appeal against the order dt.28th ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Ratio Held Legal documents amend in the above ...      0\n",
       "1  Counsel for Respondent - Ojha Honble Dr. Yeshw...      0\n",
       "2  charge sheet has been filed in the present cas...      1\n",
       "3  Coram Honble Ramesh C.J.Honble Alok Kumar Verm...      0\n",
       "4  The has this appeal against the order dt.28th ...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc8840c3-42b3-4b4e-9b26-21df3da7d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37d9f4d9-b185-456b-9566-6f97944074bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Loaded InLegalBERT.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "MODEL_NAME = \"law-ai/InLegalBERT\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded InLegalBERT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a20017e-6cb3-4b8f-a02a-655d41a24cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing TRAIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing:   0%|                                                                              | 0/589 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 512). Running this sequence through the model will result in indexing errors\n",
      "Tokenizing: 100%|████████████████████████████████████████████████████████████████████| 589/589 [16:19<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: 245780 rows removed (>512 tokens). Remaining: 55279\n",
      "\n",
      "Processing VAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|████████████████████████████████████████████████████████████████████| 169/169 [04:23<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: 70420 rows removed (>512 tokens). Remaining: 15597\n",
      "\n",
      "Processing TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████████████████████████████████████████████████████████████████| 84/84 [02:02<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: 35111 rows removed (>512 tokens). Remaining: 7897\n",
      "\n",
      "================ FINAL ROW COUNTS ================\n",
      "TRAIN rows: 55279\n",
      "VAL rows:   15597\n",
      "TEST rows:  7897\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def filter_max_tokens(df, column=\"text\", max_len=512, batch_size=512):\n",
    "    texts = df[column].astype(str).tolist()\n",
    "    token_counts = []\n",
    "\n",
    "    # batched tokenization\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Tokenizing\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            add_special_tokens=True,\n",
    "            truncation=False,\n",
    "            padding=False\n",
    "        )\n",
    "        batch_lens = [len(ids) for ids in enc[\"input_ids\"]]\n",
    "        token_counts.extend(batch_lens)\n",
    "\n",
    "    df[\"num_tokens\"] = token_counts\n",
    "\n",
    "    # filter rows <= max_len\n",
    "    before = len(df)\n",
    "    df = df[df[\"num_tokens\"] <= max_len].reset_index(drop=True)\n",
    "    after = len(df)\n",
    "\n",
    "    print(f\"Filtered: {before - after} rows removed (>{max_len} tokens). Remaining: {after}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3) Apply to train, val, and test\n",
    "# ------------------------------------------------------\n",
    "print(\"\\nProcessing TRAIN\")\n",
    "train = filter_max_tokens(train, column=\"text\", max_len=512)\n",
    "\n",
    "print(\"\\nProcessing VAL\")\n",
    "val = filter_max_tokens(val, column=\"text\", max_len=512)\n",
    "\n",
    "print(\"\\nProcessing TEST\")\n",
    "test = filter_max_tokens(test, column=\"text\", max_len=512)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Final counts\n",
    "# ------------------------------------------------------\n",
    "print(\"\\n================ FINAL ROW COUNTS ================\")\n",
    "print(f\"TRAIN rows: {len(train)}\")\n",
    "print(f\"VAL rows:   {len(val)}\")\n",
    "print(f\"TEST rows:  {len(test)}\")\n",
    "print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f0db28-dbfd-423d-86b7-c5e30eeb6513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Processing train (rows: 55279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing batches: 100%|████████████████████████████████████████████████████████████| 108/108 [00:10<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train token stats:\n",
      "  min: 55\n",
      "  max: 512\n",
      "  mean: 286.48937209428533\n",
      "  median: 284.0\n",
      "  90th percentile: 462\n",
      "\n",
      "-> Processing val (rows: 15597)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing batches: 100%|██████████████████████████████████████████████████████████████| 31/31 [00:02<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val token stats:\n",
      "  min: 56\n",
      "  max: 512\n",
      "  mean: 286.5154837468744\n",
      "  median: 284.0\n",
      "  90th percentile: 462\n",
      "\n",
      "-> Processing test (rows: 7897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing batches: 100%|██████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test token stats:\n",
      "  min: 58\n",
      "  max: 512\n",
      "  mean: 283.8234772698493\n",
      "  median: 280.0\n",
      "  90th percentile: 461\n",
      "\n",
      "Top longest in train:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text  num_tokens\n",
      "                                                                                                                                                                                                                                                                                                                                           PRESENT JUSTICE SHRI.P.Q.BARKATH ALI PRESIDENT JOSE MEMBER G. Nair, W o C.G.Nair, Kalathil House, P.O.Edakazhiyoor, COMPLAINANT Via Thrissur District.(By Adv Pavithran) Vs. Laila Mani, W o Moothedath Gopi, Moothedath House, Thrissur Desom, Thrissur Taluk, Thrissur District, Thrissur-2.R by her husband Power of Attorney agent- Moothedath Gopi, S o Unni, Moothedath House, Thrissur Desom, OPPOSITE PARTIES Thrissur Taluk, Thrissur District, Thrissur-2.Sanil Kumar Kanissery, S o late Menon, Acharia, Nagar, Cochi - 36.JUDGMENT JUSTICE BARKATH ALI PRESIDENT This is a complaint filed by the complainant under section 17 of the Consumer Protection Act, 1986 claiming refund of the amount given to the respondents for building a flat.Complainant has also claimed compensation as well as a direction to direct the opposite parties to register a sale deed with respect to the land and building.The case of the complainant as stated in the complaint in brief is this Opposite parties1 and 2 are the owner and builder of petition flat and land and an was them on March 30, 2006 by which the builder has agreed to develop the landed property and construct a multi storied building complex known as Grandeur Westend Palace at Thrippunithura and allot flat No.5 to the complainant.Under the said complainant paid to the opposite parties, on the date of and on November 16, 2008.But so far as opposite parties have not handed over of the said flat to the complainant.complainant filed the complaint for a direction directing the opposite parties to hand over of flat No.5 in the building complex by name Grandeur Westend Palace at Thrippunithura described in the schedule to the said Complainant has also sought for a direction directing the opposite parties to register sale deed in respect of the said property to the complainant.He claimed a compensation of and cost.Though opposite parties 1 and 2 notice they remained absent.complainant filed proof affidavit and Exts.A1 and A2 were marked on his side.         512\n",
      "                the order inter alia that it was conceded before the Court that Mr. Mangal ram was duly appointed as Land Collector, Panchkula to give the award dated and though it is not specifically so recorded in the judgment, as on principle, it has been accepted that the award given by a not duly appointed Collector is a void award.Consequently, the impugned order is liable to be and the award given by Mr. is liable to be set aside.The learned counsel in order to support his produced again today before us the issued u s 3 of the Land Act dated which runs as under- The following officers to perform the functions of CWP No.1614 of 1990 and other connected case 3 the Collector under the Act in the State- Shri Mangal Ram Urban Estate, Panchkula.It was further pointed out that the Director, Urban Estates, Panchkula ordered on 26.6.1988 that Mr. Mangal Ram Land Officer, at Panchkula will also look after the work of Land Officer, Panchkula till further orders.It is contended that the Director, Urban Estates had no authority to appoint the Land Collector.In our considered view, reading of the in its pith and substance left us with no other discernible that Mr. Mangal Ram was appointed Land Collector under the Act for as well as for Panchkula.has to be given to make a workable and not to render the acts of the State as negated.Mere issuance of the order by the Director, Urban Estates will not change the character of of appointment of a Collector by the State.It may be observed by way of or under some assumption made by the Director of Urban Estates with respect to the discharge of functions as a Land Officer by Mr. Mangal However, the put by the Director, Urban Estates will not change the character of the As we have observed that the has categorically conferred the power of a Collector for as well as CWP No.1614 of 1990 and other connected case 4 Panchkula, the award has been given by a duly authorized person i.e.Collector, Land Panchkula.No other point has been raised by the learned counsel.The objection of the petitioner therein that the officer, who had passed an Award, was not notified as a Land Collector was negated by this Court and it was held that the Award has rightly been passed.Counsel for the petitioners made a to the facts of this case from the case.However, he failed to do so.         512\n",
      "Devadoss, J.The only point in this case is whether the alienation under Ex.F is binding upon the plaintiff.Under Ex.F the property belonging to the plaintiffs father and property which the plaintiffs mother, the 1st defendant, inherited from her parents were sold to the Defendants 2 and 3 for Rs.600.Both Courts have the plaintiff s suit.The plaintiff has this second appeal.Mr. Rajah Aiyar for the appellants contends that the sale of the ancestral properties belonging to the plaintiff and his father is not binding upon him, inasmuch as there was no necessity at the time for the sale of the property.Both the Courts have come to the conclusion that the plaintiffs father was obliged to sell the property, for he was not living in the place, he hardly had any income, he was living at a distance as a cook and it was necessary to the plaintiff s who was about or twelve years of age on the date of the sale, and the sale was not only for a necessity, but also a prudent act of management.Mr. Rajah Aiyars is that there must be actual necessity to bring the case within the principle of the decision in Hanuman Pershads case 1855 6 M. I.A.393 and that in order to justify a fathers sale of property belonging to his son there should be such pressure as could not be in any other way.If at the time the property is sold he is unable to support his family from the income of the property and if has no other substantial income and if by selling the property he could maintain the family or at least provide funds for its a Hindu father is justified in selling the ancestral property conveying the share of the son also.In this case the are such from which it could be reasonably inferred that at the time of sale there was necessity to sell the property in order to maintain the family.Mr. Rajah Aiyars is that the father must have earned money as a cook and he was not justified in selling the property and getting a mortgage for the sale amount.But it is not possible now to say what were the actual which the sale.As the lower Courts point out, the man was living at a considerable distance, he was poor, the boys had to be performed and there were other calls on the purse and the sale by the father of the plaintiffs ancestral property was for the proper purposes of the family and the sale is binding upon the plaintiff.         512\n",
      "                                                                  G. Chacko, Member (J) This appeal by the is against rejection of a refund claim.There is no for the appellants despite notice, nor any request of theirs for adjournment.We are inclined to dispose of this old appeal after examining the records, carefully considering the grounds of the appeal and hearing ld.SDR.Accordingly, the appeal is taken up.M s. Power Ltd. (appellants) had cleared a of epoxy insulated coils along with under Bill of Entry dt.24.12.91 on payment of duties of customs as applicable to Heading 85.44 of the First Schedule to the Customs Tariff Act (for the purpose of Basic Customs Duty) and Heading 85.44 of the Schedule to the Central Excise Tariff Act (for the purpose of Additional Duty of Customs).Subsequently, they the Asst.Collector of Customs for the goods under Heading 85.03 and granting consequential relief of refund of excess duty paid.This claim was by the who confirmed of the goods under SH 8544.11.The first appellate authority affirmed the decision of the lower authority.Hence the present appeal against the appellate order.It appears from the records that the was not challenged by the in with law.They chose to challenge it by way of a refund claim, wherein they disputed the of the goods and wanted the goods to be classified under Heading 85.03 for the purpose of refund of excess duty.Throughout the grounds of this appeal, the appellants have urged reasons for classifying the goods under Heading 85.03 and have also claimed the benefit of Customs No.172/89 dt.Ld.SDR submits that such grounds could be raised only in an appeal filed against the order and not in a refund claim filed without challenging the In this ld.SDR relies on the apex courts judgment in Priya Blue Industries Ltd. v. CC , wherein it was held that refund claim contrary to order was not under Section 27 of the Customs Act.Admittedly, in the present case, the appellants classified the goods under Heading 85.44 (SH 8544.11) and cleared the goods voluntarily on payment of duty.The order, which was countersigned by the Asst.Commissioner, was but it was not appealed against.The chose to challenge the by way of a refund claim, which was not permissible in law.The refund claim is clearly hit by the ruling of the apex court cited by ld.SDR.         512\n",
      "                                                                                                                                                           G. Chacko, Member (J) The appellants are manufacturers of herbal shampoo.They used to entrust the work of repacking the commodity from bulk containers to retail containers, to their job workers.At the end of the job workers.there occurs processing loss to the tune of 2.In other words, the quantity of repacked shampoo back by the appellants from the job workers is less by 2.In respect of this shortage, the department proposed to recover differential Modvat Credit under Rule 571 of the Central Excise Rules.1944 for the period of dispute.Show cause notices this proposal were issued and the same were contested.Original authority confirmed the demand under rule 571 ibid.Its decision was sustained by the Commissioner (Appeals).Hence the present appeals of the Learned Counsel for the appellants submits that they were eligible under Rule 57D (1) for the credit of duty paid on the quantity of shampoo (2) which became waste at the job workers end.He has in his relied upon the Boards Circular No.267/136/87-CD.8 dated as also on the following decisions of the Tribunal Godrej Soaps Ltd. v. CCE, Mumbai reported in 2002 (50) RLT (CEGAT-Mum.)CCE.Madras v. Bush Boake Allen (I) Ltd. Reported in 2001 (47) RLT 712 (CEGAT-Che.)Learned SDR the findings of the Commissioner (Appeals) and points out that the waste of shampoo in the instant case is not analogous to the input loss considered in the Boards Circular.After considering the 1 find that admittedly 2 of shampoo happened to be wasted during the course of repacking activity in the job workers premises.This wastage occurred in or in relation to the manufacture of the final product i.e.shampoo in retail pack.Sub Rule (1) of Rule 57D, as this rule stood at the material time, allowed Modvat credit on such input waste.This legal position was recognised in the case of Godrej Soaps Ltd. (supra) .The decision of the 2-Member Bench in the case of Bush Boake Allen (I) Ltd. (supra) is also in support of this legal position.Appellants have thus established their claim for Modvat Credit on the 2 input waste on the strength of Rule 57D and the cited case law, though they cannot claim support from the Boards Circular.         512\n"
     ]
    }
   ],
   "source": [
    "# 2) helper to batch-tokenize and count tokens\n",
    "def count_tokens_in_df(df, text_col=\"text\", batch_size=512, add_column=True):\n",
    "    \"\"\"\n",
    "    Returns a list of token counts for each row in df[text_col].\n",
    "    If add_column=True, adds a 'num_tokens' column to df (inplace).\n",
    "    \"\"\"\n",
    "    texts = df[text_col].astype(str).tolist()\n",
    "    n = len(texts)\n",
    "    token_counts = [0] * n\n",
    "\n",
    "    # process in batches to avoid huge memory peaks\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Tokenizing batches\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        # tokenize without padding (we only need lengths); disable truncation so you see full length\n",
    "        enc = tokenizer(batch_texts, add_special_tokens=True, truncation=False, padding=False)\n",
    "        batch_lengths = [len(ids) for ids in enc[\"input_ids\"]]\n",
    "        token_counts[i : i + batch_size] = batch_lengths\n",
    "    return token_counts\n",
    "\n",
    "# 3) Run it on your datasets\n",
    "# (Assumes `train`, `val`, `test` are pandas DataFrames already in the notebook)\n",
    "for name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "    print(f\"\\n-> Processing {name} (rows: {len(df)})\")\n",
    "    count_tokens_in_df(df, text_col=\"text\", batch_size=512, add_column=True)\n",
    "\n",
    "    # quick stats\n",
    "    print(f\"{name} token stats:\")\n",
    "    print(\"  min:\", int(df[\"num_tokens\"].min()))\n",
    "    print(\"  max:\", int(df[\"num_tokens\"].max()))\n",
    "    print(\"  mean:\", float(df[\"num_tokens\"].mean()))\n",
    "    print(\"  median:\", float(df[\"num_tokens\"].median()))\n",
    "    print(\"  90th percentile:\", int(df[\"num_tokens\"].quantile(0.9)))\n",
    "\n",
    "# 4) Optionally inspect top-longest examples\n",
    "def show_longest(df, k=5):\n",
    "    print(df.sort_values(\"num_tokens\", ascending=False)[[\"text\", \"num_tokens\"]].head(k).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop longest in train:\")\n",
    "show_longest(train, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df7fc5c-c4ca-4bfa-bb52-3aab3853db27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heard the learned counsel for the petitioner a...</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All the above mentioned contempt petitions sha...</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MR. JUSTICE AKHTAR HUSAIN KHAN (ORAL) Present ...</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE HONBLE JUSTICE SMT.PRAKASH Anjana Prakash,...</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To question the correctness of the order dated...</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  num_tokens\n",
       "0  Heard the learned counsel for the petitioner a...      0         225\n",
       "1  All the above mentioned contempt petitions sha...      0         239\n",
       "2  MR. JUSTICE AKHTAR HUSAIN KHAN (ORAL) Present ...      0         415\n",
       "3  THE HONBLE JUSTICE SMT.PRAKASH Anjana Prakash,...      0         361\n",
       "4  To question the correctness of the order dated...      0         132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "869ab826-e291-4c36-87ab-c1c17bc8ca66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting TRAIN embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS embeddings: 100%|████████████████████████████████████████████████| 1728/1728 [22:54<00:00,  1.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_cls shape: (55279, 768)\n",
      "\n",
      "Extracting VAL embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS embeddings: 100%|██████████████████████████████████████████████████| 488/488 [06:22<00:00,  1.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val_cls shape: (15597, 768)\n",
      "\n",
      "Extracting TEST embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CLS embeddings: 100%|██████████████████████████████████████████████████| 247/247 [02:36<00:00,  1.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_cls shape: (7897, 768)\n",
      "\n",
      "Sanity checks:\n",
      "Train labels counts: {0: 28666, 1: 26613}\n",
      "Shapes (train/val/test): (55279, 768) (15597, 768) (7897, 768)\n",
      "Embedding dtype: float32\n",
      "First train embedding (vector preview, first 6 elements):\n",
      "[-0.10805389 -0.03798876  0.34646943 -0.33456892  0.6474604   0.17861015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_cls_embeddings_from_texts(\n",
    "    texts,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    device,\n",
    "    batch_size=32,\n",
    "    max_length=512,\n",
    "    show_progress=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a list of texts, returns numpy array (n_texts, hidden_size) containing CLS embeddings.\n",
    "    Uses outputs.last_hidden_state[:, 0, :] as CLS.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embs = []\n",
    "    n = len(texts)\n",
    "    iterator = range(0, n, batch_size)\n",
    "    if show_progress:\n",
    "        iterator = tqdm(iterator, desc=\"Extracting CLS embeddings\", unit=\"batch\")\n",
    "\n",
    "    try:\n",
    "        for start in iterator:\n",
    "            batch_texts = texts[start : start + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\",\n",
    "                return_attention_mask=True\n",
    "            )\n",
    "            input_ids = enc[\"input_ids\"].to(device)\n",
    "            attention_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                cls = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # (b, hidden)\n",
    "                all_embs.append(cls)\n",
    "\n",
    "        all_embs = np.vstack(all_embs)\n",
    "        return all_embs\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Likely OOM\n",
    "        err = str(e).lower()\n",
    "        if \"out of memory\" in err or \"cuda\" in err:\n",
    "            print(\"\\nRuntimeError (likely OOM). Try reducing batch_size or use CPU.\")\n",
    "            print(\"Suggested actions:\")\n",
    "            print(\" - set batch_size to a smaller value (e.g., 8 or 4).\")\n",
    "            print(\" - or run on CPU: device = torch.device('cpu') and move model to CPU.\")\n",
    "        raise\n",
    "\n",
    "# ----- 3) Run extraction for train/val/test -----\n",
    "# Choose a safe default batch size. If you have a big GPU, increase it.\n",
    "DEFAULT_BATCH_SIZE = 32\n",
    "\n",
    "print(\"\\nExtracting TRAIN embeddings...\")\n",
    "train_texts = train[\"text\"].astype(str).tolist()\n",
    "X_train_cls = extract_cls_embeddings_from_texts(\n",
    "    train_texts, tokenizer, model, device, batch_size=DEFAULT_BATCH_SIZE, max_length=512\n",
    ")\n",
    "print(\"X_train_cls shape:\", X_train_cls.shape)\n",
    "\n",
    "print(\"\\nExtracting VAL embeddings...\")\n",
    "val_texts = val[\"text\"].astype(str).tolist()\n",
    "X_val_cls = extract_cls_embeddings_from_texts(\n",
    "    val_texts, tokenizer, model, device, batch_size=DEFAULT_BATCH_SIZE, max_length=512\n",
    ")\n",
    "print(\"X_val_cls shape:\", X_val_cls.shape)\n",
    "\n",
    "print(\"\\nExtracting TEST embeddings...\")\n",
    "test_texts = test[\"text\"].astype(str).tolist()\n",
    "X_test_cls = extract_cls_embeddings_from_texts(\n",
    "    test_texts, tokenizer, model, device, batch_size=DEFAULT_BATCH_SIZE, max_length=512\n",
    ")\n",
    "print(\"X_test_cls shape:\", X_test_cls.shape)\n",
    "\n",
    "# ----- 4) Quick sanity previews -----\n",
    "print(\"\\nSanity checks:\")\n",
    "print(\"Train labels counts:\", train['label'].value_counts().to_dict())\n",
    "print(\"Shapes (train/val/test):\", X_train_cls.shape, X_val_cls.shape, X_test_cls.shape)\n",
    "print(\"Embedding dtype:\", X_train_cls.dtype)\n",
    "print(\"First train embedding (vector preview, first 6 elements):\")\n",
    "print(X_train_cls[0, :6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81a7ce10-e1b4-49ea-9804-bce01df3a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved embeddings to folder: inlegalbert_cls_embeddings (files: X_train_cls.npy, X_val_cls.npy, X_test_cls.npy)\n"
     ]
    }
   ],
   "source": [
    "# ----- 5) Optionally save embeddings to disk (uncomment to enable) -----\n",
    "out_dir = \"inlegalbert_cls_embeddings\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "np.save(os.path.join(out_dir, \"X_train_cls.npy\"), X_train_cls)\n",
    "np.save(os.path.join(out_dir, \"X_val_cls.npy\"), X_val_cls)\n",
    "np.save(os.path.join(out_dir, \"X_test_cls.npy\"), X_test_cls)\n",
    "print(f\"\\nSaved embeddings to folder: {out_dir} (files: X_train_cls.npy, X_val_cls.npy, X_test_cls.npy)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225f0495-a44f-45f5-8f74-74be1849be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "     ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/8.9 MB 2.0 MB/s eta 0:00:05\n",
      "      --------------------------------------- 0.2/8.9 MB 2.5 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.4/8.9 MB 3.1 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.5/8.9 MB 3.4 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.7/8.9 MB 3.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.9/8.9 MB 3.7 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.1/8.9 MB 3.8 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.4/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.5/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 1.8/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 1.9/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.2/8.9 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.4/8.9 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.6/8.9 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 2.9/8.9 MB 4.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.2/8.9 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 3.5/8.9 MB 5.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 3.8/8.9 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 4.0/8.9 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 4.4/8.9 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 4.8/8.9 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 5.0/8.9 MB 5.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 5.3/8.9 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 5.5/8.9 MB 5.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 6.0/8.9 MB 5.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 6.3/8.9 MB 5.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 6.7/8.9 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 6.9/8.9 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 7.3/8.9 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 7.7/8.9 MB 6.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 7.9/8.9 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 8.3/8.9 MB 6.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 8.7/8.9 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.9/8.9 MB 6.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.9/8.9 MB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "     ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "     -------------------------------------  307.2/308.4 kB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 308.4/308.4 kB 6.3 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "     ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/41.3 MB 5.7 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.6/41.3 MB 6.5 MB/s eta 0:00:07\n",
      "      --------------------------------------- 0.8/41.3 MB 5.9 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.1/41.3 MB 6.5 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.3/41.3 MB 6.6 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.6/41.3 MB 6.2 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.9/41.3 MB 6.4 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.1/41.3 MB 6.1 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.4/41.3 MB 6.5 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.8/41.3 MB 6.6 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.1/41.3 MB 6.8 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.4/41.3 MB 6.6 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 3.7/41.3 MB 6.8 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 4.1/41.3 MB 6.9 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.4/41.3 MB 6.9 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 4.8/41.3 MB 6.9 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 5.1/41.3 MB 7.0 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 5.4/41.3 MB 7.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 5.8/41.3 MB 7.2 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 6.1/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 6.5/41.3 MB 7.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 6.8/41.3 MB 7.2 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 7.1/41.3 MB 7.2 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 7.4/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 7.6/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 7.8/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 8.1/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 8.4/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 8.6/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 9.0/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 9.3/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 9.6/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 9.8/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 10.1/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 10.4/41.3 MB 7.1 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 10.8/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 11.0/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 11.3/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 11.5/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 11.8/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 12.0/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 12.3/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 12.5/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 12.8/41.3 MB 7.0 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 13.1/41.3 MB 6.9 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 13.4/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 13.8/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 14.1/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 14.4/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 14.7/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 15.1/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 15.4/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 15.8/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 16.1/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 16.5/41.3 MB 6.8 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 16.8/41.3 MB 6.8 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.0/41.3 MB 6.8 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 17.4/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 17.6/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 18.0/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 18.3/41.3 MB 6.9 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 18.7/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 18.9/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 19.3/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 19.6/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 19.8/41.3 MB 7.0 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 20.1/41.3 MB 7.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 20.4/41.3 MB 7.0 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 20.6/41.3 MB 6.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.0/41.3 MB 6.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.2/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.4/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 21.6/41.3 MB 6.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 21.9/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 22.1/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 22.4/41.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 22.7/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 23.1/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 23.3/41.3 MB 6.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 23.6/41.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 23.8/41.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.0/41.3 MB 6.7 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.2/41.3 MB 6.6 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 24.5/41.3 MB 6.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 24.8/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.1/41.3 MB 6.6 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.4/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 25.6/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 25.9/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 26.2/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 26.5/41.3 MB 6.6 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 26.8/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 27.1/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 27.4/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     -------------------------- ------------- 27.7/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 28.1/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 28.2/41.3 MB 6.5 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 28.7/41.3 MB 6.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 28.9/41.3 MB 6.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.2/41.3 MB 6.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.3/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.7/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 29.9/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.1/41.3 MB 6.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.4/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.6/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 30.9/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.1/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.3/41.3 MB 6.4 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.5/41.3 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.7/41.3 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 31.9/41.3 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.1/41.3 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.2/41.3 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.4/41.3 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.5/41.3 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.7/41.3 MB 6.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 32.9/41.3 MB 6.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.2/41.3 MB 5.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.4/41.3 MB 5.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.6/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 33.8/41.3 MB 5.8 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.1/41.3 MB 5.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.2/41.3 MB 5.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.4/41.3 MB 5.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.6/41.3 MB 5.7 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.8/41.3 MB 5.6 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 34.9/41.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 35.2/41.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 35.4/41.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 35.6/41.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 35.8/41.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 36.1/41.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 36.3/41.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 36.4/41.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 36.5/41.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 36.8/41.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 37.0/41.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 37.2/41.3 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 37.5/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 37.7/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 37.9/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 38.1/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 38.3/41.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 38.6/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 38.9/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 39.2/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 39.4/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 39.6/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 39.9/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.1/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.4/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.6/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  40.8/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.1/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.3/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.3/41.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 41.3/41.3 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb6cf25f-d580-4036-aea0-cbe9f50e2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a3a48d-5428-47d1-83f6-82b5b0e0fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading xgboost-3.1.2-py3-none-win_amd64.whl (72.0 MB)\n",
      "     ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/72.0 MB 2.6 MB/s eta 0:00:28\n",
      "     ---------------------------------------- 0.2/72.0 MB 3.5 MB/s eta 0:00:21\n",
      "     ---------------------------------------- 0.5/72.0 MB 4.3 MB/s eta 0:00:17\n",
      "     ---------------------------------------- 0.6/72.0 MB 4.7 MB/s eta 0:00:16\n",
      "     ---------------------------------------- 0.8/72.0 MB 4.5 MB/s eta 0:00:16\n",
      "      --------------------------------------- 1.0/72.0 MB 4.5 MB/s eta 0:00:16\n",
      "      --------------------------------------- 1.1/72.0 MB 4.2 MB/s eta 0:00:17\n",
      "      --------------------------------------- 1.4/72.0 MB 4.5 MB/s eta 0:00:16\n",
      "      --------------------------------------- 1.5/72.0 MB 4.6 MB/s eta 0:00:16\n",
      "      --------------------------------------- 1.8/72.0 MB 4.7 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 1.9/72.0 MB 4.8 MB/s eta 0:00:15\n",
      "     - -------------------------------------- 2.1/72.0 MB 4.8 MB/s eta 0:00:15\n",
      "     - -------------------------------------- 2.2/72.0 MB 4.5 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 2.3/72.0 MB 4.4 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 2.5/72.0 MB 4.4 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 2.6/72.0 MB 4.4 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 2.7/72.0 MB 4.2 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 2.8/72.0 MB 4.1 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 3.0/72.0 MB 4.1 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 3.0/72.0 MB 4.0 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 3.2/72.0 MB 4.0 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 3.3/72.0 MB 4.0 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 3.5/72.0 MB 3.9 MB/s eta 0:00:18\n",
      "     - -------------------------------------- 3.5/72.0 MB 3.8 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 3.6/72.0 MB 3.8 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 3.8/72.0 MB 3.7 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 3.9/72.0 MB 3.7 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 4.1/72.0 MB 3.8 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 4.2/72.0 MB 3.8 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 4.4/72.0 MB 3.7 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 4.6/72.0 MB 3.8 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 4.8/72.0 MB 3.8 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 4.9/72.0 MB 3.7 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 5.1/72.0 MB 3.8 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 5.2/72.0 MB 3.7 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 5.3/72.0 MB 3.7 MB/s eta 0:00:18\n",
      "     --- ------------------------------------ 5.4/72.0 MB 3.7 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 5.6/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 5.7/72.0 MB 3.7 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 5.8/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 5.9/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.1/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.2/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.4/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.5/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.6/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 6.8/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 7.0/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 7.1/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     --- ------------------------------------ 7.2/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.3/72.0 MB 3.6 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.4/72.0 MB 3.5 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.5/72.0 MB 3.5 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.6/72.0 MB 3.5 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.7/72.0 MB 3.5 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 7.9/72.0 MB 3.4 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 8.0/72.0 MB 3.4 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 8.1/72.0 MB 3.4 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 8.2/72.0 MB 3.4 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 8.4/72.0 MB 3.4 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 8.4/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 8.5/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 8.6/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 8.7/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 8.9/72.0 MB 3.3 MB/s eta 0:00:19\n",
      "     ---- ----------------------------------- 9.0/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ---- ----------------------------------- 9.0/72.0 MB 3.3 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.0/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.2/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.3/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.4/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.5/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.7/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 9.9/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.0/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.1/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.2/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.3/72.0 MB 3.2 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.4/72.0 MB 3.1 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.5/72.0 MB 3.1 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.6/72.0 MB 3.1 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.6/72.0 MB 3.1 MB/s eta 0:00:20\n",
      "     ----- ---------------------------------- 10.8/72.0 MB 3.1 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 10.9/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.0/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.1/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.2/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.4/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.4/72.0 MB 3.0 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.6/72.0 MB 2.9 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.7/72.0 MB 2.9 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.8/72.0 MB 2.9 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 11.9/72.0 MB 2.9 MB/s eta 0:00:21\n",
      "     ------ --------------------------------- 12.0/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 12.1/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 12.2/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 12.3/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 12.5/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------ --------------------------------- 12.6/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 12.7/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 12.8/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 12.9/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 13.0/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 13.1/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 13.2/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 13.4/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 13.5/72.0 MB 2.8 MB/s eta 0:00:22\n",
      "     ------- -------------------------------- 13.6/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 13.7/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 13.9/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 14.0/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 14.1/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     ------- -------------------------------- 14.3/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 14.4/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 14.6/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 14.7/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 14.8/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 14.9/72.0 MB 2.7 MB/s eta 0:00:22\n",
      "     -------- ------------------------------- 15.1/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 15.2/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 15.4/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 15.6/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 15.7/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 15.9/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 16.0/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     -------- ------------------------------- 16.1/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 16.2/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 16.4/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 16.5/72.0 MB 2.8 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 16.7/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 16.8/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 17.0/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 17.2/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 17.3/72.0 MB 2.7 MB/s eta 0:00:21\n",
      "     --------- ------------------------------ 17.6/72.0 MB 2.8 MB/s eta 0:00:20\n",
      "     --------- ------------------------------ 17.7/72.0 MB 2.8 MB/s eta 0:00:20\n",
      "     --------- ------------------------------ 17.9/72.0 MB 2.8 MB/s eta 0:00:20\n",
      "     ---------- ----------------------------- 18.1/72.0 MB 2.8 MB/s eta 0:00:20\n",
      "     ---------- ----------------------------- 18.3/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 18.4/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 18.6/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 18.8/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 19.0/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 19.0/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 19.1/72.0 MB 2.9 MB/s eta 0:00:19\n",
      "     ---------- ----------------------------- 19.4/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 19.5/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ---------- ----------------------------- 19.7/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 19.8/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 20.0/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 20.1/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 20.3/72.0 MB 3.0 MB/s eta 0:00:18\n",
      "     ----------- ---------------------------- 20.4/72.0 MB 3.0 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 20.5/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 20.6/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 20.8/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 20.9/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 21.1/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 21.2/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 21.4/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ----------- ---------------------------- 21.5/72.0 MB 3.1 MB/s eta 0:00:17\n",
      "     ------------ --------------------------- 21.6/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 21.8/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 21.9/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 22.1/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 22.3/72.0 MB 3.3 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 22.4/72.0 MB 3.3 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 22.6/72.0 MB 3.3 MB/s eta 0:00:16\n",
      "     ------------ --------------------------- 22.7/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------ --------------------------- 22.9/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------ --------------------------- 23.0/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------ --------------------------- 23.2/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------ --------------------------- 23.3/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.4/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.4/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.5/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.5/72.0 MB 3.3 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.6/72.0 MB 3.2 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.7/72.0 MB 3.2 MB/s eta 0:00:15\n",
      "     ------------- -------------------------- 23.8/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 23.8/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 23.8/72.0 MB 3.2 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 23.9/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.0/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.1/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.2/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.4/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.5/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.6/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.7/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.8/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 24.9/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 25.0/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     ------------- -------------------------- 25.1/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.2/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.4/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.5/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.6/72.0 MB 3.1 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.8/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 25.9/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.0/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.1/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.2/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.2/72.0 MB 3.0 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.3/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.4/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.5/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.6/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.7/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.8/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     -------------- ------------------------- 26.9/72.0 MB 2.9 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.1/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.2/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.2/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.4/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.5/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.6/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.7/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 27.8/72.0 MB 2.8 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 27.9/72.0 MB 2.8 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 27.9/72.0 MB 2.8 MB/s eta 0:00:16\n",
      "     --------------- ------------------------ 28.1/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.3/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.4/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.4/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.5/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.6/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     --------------- ------------------------ 28.7/72.0 MB 2.7 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 28.8/72.0 MB 2.6 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 28.9/72.0 MB 2.6 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 28.9/72.0 MB 2.6 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 28.9/72.0 MB 2.6 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.1/72.0 MB 2.6 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.2/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.2/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.3/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.4/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.5/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.6/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.7/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.8/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 29.9/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.0/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.1/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.2/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.4/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.5/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ---------------- ----------------------- 30.6/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 30.7/72.0 MB 2.5 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 30.7/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 30.9/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.0/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.1/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.1/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.3/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.4/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.5/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.6/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.7/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.8/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 31.9/72.0 MB 2.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 32.0/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 32.1/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 32.1/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 32.2/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 32.3/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 32.3/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.4/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.5/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.6/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.6/72.0 MB 2.3 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.7/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.8/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 32.9/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.0/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.1/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.2/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.2/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.3/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.5/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.5/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.7/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.8/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.9/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 33.9/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 34.0/72.0 MB 2.2 MB/s eta 0:00:18\n",
      "     ------------------ --------------------- 34.1/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 34.1/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 34.2/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.3/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.4/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.5/72.0 MB 2.3 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.6/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.7/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.8/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 34.8/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.0/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.1/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.1/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.3/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.3/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.4/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.5/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.6/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.7/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.8/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.8/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 35.9/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.1/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.1/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.2/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.3/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.4/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.5/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.6/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.7/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.8/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 36.9/72.0 MB 2.2 MB/s eta 0:00:17\n",
      "     -------------------- ------------------- 37.0/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.1/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.3/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.4/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.6/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.7/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 37.8/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 37.9/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.0/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.1/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.3/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.4/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.4/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.5/72.0 MB 2.2 MB/s eta 0:00:16\n",
      "     --------------------- ------------------ 38.6/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 38.7/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 38.8/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 38.9/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.0/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.1/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.2/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.3/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.4/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.5/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.5/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 39.5/72.0 MB 2.3 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.6/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.6/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.7/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.7/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.8/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.9/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 39.9/72.0 MB 2.2 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 40.0/72.0 MB 2.1 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 40.0/72.0 MB 2.1 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 40.0/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.1/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.1/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.2/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.3/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.4/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.5/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.6/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.6/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.7/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.8/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.8/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 40.9/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.0/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.0/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.1/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.1/72.0 MB 2.1 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.2/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.2/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.3/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 41.4/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.4/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.5/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.6/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.6/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.7/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.8/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 41.9/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.0/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.1/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.1/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.2/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.3/72.0 MB 2.0 MB/s eta 0:00:16\n",
      "     ----------------------- ---------------- 42.4/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.5/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.6/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.7/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.8/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.9/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 42.9/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 43.0/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 43.1/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 43.2/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.2/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.4/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.4/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.5/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.6/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.7/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.8/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 43.9/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 44.0/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 44.0/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 44.1/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 44.2/72.0 MB 2.0 MB/s eta 0:00:15\n",
      "     ------------------------ --------------- 44.3/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.4/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.5/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.6/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.7/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.8/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 44.9/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 45.0/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.1/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.2/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.3/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.4/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.5/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.5/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.6/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.7/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.8/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 45.9/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 46.0/72.0 MB 2.0 MB/s eta 0:00:14\n",
      "     ------------------------- -------------- 46.2/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.2/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.4/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.5/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.6/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.6/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 46.8/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 46.8/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.0/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.0/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.2/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.3/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.4/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.5/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.6/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.6/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.7/72.0 MB 2.0 MB/s eta 0:00:13\n",
      "     -------------------------- ------------- 47.9/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 47.9/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 48.1/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 48.3/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 48.4/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 48.5/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 48.6/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 48.8/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 48.9/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 49.0/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 49.2/72.0 MB 2.0 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 49.4/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 49.5/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 49.6/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 49.7/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 49.8/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 50.0/72.0 MB 2.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 50.1/72.0 MB 2.2 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 50.3/72.0 MB 2.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 50.4/72.0 MB 2.2 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 50.6/72.0 MB 2.3 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 50.7/72.0 MB 2.3 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 50.9/72.0 MB 2.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.1/72.0 MB 2.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.2/72.0 MB 2.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.4/72.0 MB 2.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.6/72.0 MB 2.5 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.7/72.0 MB 2.5 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 51.9/72.0 MB 2.5 MB/s eta 0:00:08\n",
      "     ---------------------------- ----------- 52.0/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ---------------------------- ----------- 52.2/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.3/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.4/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.5/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.6/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.8/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.8/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 52.9/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 53.0/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 53.0/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 53.1/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 53.3/72.0 MB 2.6 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 53.4/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 53.5/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 53.6/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 53.8/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ----------------------------- ---------- 53.9/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.1/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.2/72.0 MB 2.7 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.3/72.0 MB 2.8 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.5/72.0 MB 2.8 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.7/72.0 MB 2.8 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 54.8/72.0 MB 2.8 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 55.0/72.0 MB 2.8 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 55.1/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.2/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.3/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.4/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.5/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.6/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------ --------- 55.7/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 55.8/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 55.9/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.0/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.1/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.2/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.3/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.4/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.4/72.0 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.5/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.5/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.5/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.5/72.0 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.6/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.7/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.8/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.8/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 56.9/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.0/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.1/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.3/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.4/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.4/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------------- -------- 57.5/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 57.6/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 57.7/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 57.8/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 57.9/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.0/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.1/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.1/72.0 MB 2.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.2/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.3/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.4/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.5/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.6/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.7/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.8/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 58.9/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 59.1/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 59.1/72.0 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 59.2/72.0 MB 2.5 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 59.3/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.5/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.5/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.7/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.8/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.9/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 59.9/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.1/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.1/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.3/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.3/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.4/72.0 MB 2.5 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.6/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.6/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.7/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 60.9/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 61.0/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 61.1/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 61.2/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.3/72.0 MB 2.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.3/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.4/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.5/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.7/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.8/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 61.9/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.0/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.0/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.1/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.2/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.3/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.4/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.5/72.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.6/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.6/72.0 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.7/72.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.8/72.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 62.9/72.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 63.0/72.0 MB 2.2 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 63.1/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.2/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.3/72.0 MB 2.3 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.4/72.0 MB 2.3 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.5/72.0 MB 2.3 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.6/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.7/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.8/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 63.9/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.0/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.1/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.2/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.3/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.4/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.5/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.5/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 64.7/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 64.8/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 64.9/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.0/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.1/72.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.1/72.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.2/72.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.4/72.0 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.4/72.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.5/72.0 MB 2.1 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 65.6/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 65.7/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 65.7/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 65.8/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 65.9/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.0/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.1/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.2/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.3/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.4/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.5/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 66.6/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 66.7/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 66.8/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 66.9/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.1/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.1/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.3/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.3/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.4/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.4/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.4/72.0 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.5/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.5/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.5/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.6/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.7/72.0 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 67.8/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 67.9/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 68.0/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 68.1/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 68.2/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 68.3/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 68.5/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 68.6/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 68.7/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 68.9/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.0/72.0 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.1/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.2/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.3/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.4/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.6/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.6/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.7/72.0 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 69.9/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 69.9/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 70.0/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 70.1/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.2/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.3/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.4/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.4/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.6/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.7/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.8/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.9/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.0/72.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.0/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.2/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.2/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.3/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.4/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.5/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.6/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.7/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.8/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  71.9/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  72.0/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  72.0/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  72.0/72.0 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 72.0/72.0 MB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: numpy in c:\\documents\\projects\\minor1_appeal_approval\\jupyter\\venv\\lib\\site-packages (from xgboost) (2.2.6)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9598c66d-c393-4b0c-9d41-a6122a2d0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings found in memory.\n",
      "Shapes (train/val/test): (55279, 768) (15597, 768) (7897, 768)\n",
      "Label counts (train): [28666 26613]\n",
      "Label counts (val): [8163 7434]\n",
      "Label counts (test): [4098 3799]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_train_cls  # noqa: F821\n",
    "    X_val_cls\n",
    "    X_test_cls\n",
    "    print(\"Embeddings found in memory.\")\n",
    "except NameError:\n",
    "    print(\"Embeddings not found in memory — loading from inlegalbert_cls_embeddings/*.npy\")\n",
    "    X_train_cls = np.load(\"inlegalbert_cls_embeddings/X_train_cls.npy\")\n",
    "    X_val_cls = np.load(\"inlegalbert_cls_embeddings/X_val_cls.npy\")\n",
    "    X_test_cls = np.load(\"inlegalbert_cls_embeddings/X_test_cls.npy\")\n",
    "\n",
    "# Labels\n",
    "y_train = train[\"label\"].to_numpy()\n",
    "y_val = val[\"label\"].to_numpy()\n",
    "y_test = test[\"label\"].to_numpy()\n",
    "\n",
    "print(\"Shapes (train/val/test):\", X_train_cls.shape, X_val_cls.shape, X_test_cls.shape)\n",
    "print(\"Label counts (train):\", np.bincount(y_train))\n",
    "print(\"Label counts (val):\", np.bincount(y_val))\n",
    "print(\"Label counts (test):\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c761224-daf5-423e-8c7d-d4a96d61bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fbda8-9bc2-4360-afdf-de4e99a70716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e86972-5a0f-4969-9e28-813d489e5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 1) Scale features ----------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_cls)\n",
    "X_val_scaled = scaler.transform(X_val_cls)\n",
    "X_test_scaled = scaler.transform(X_test_cls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6115ffc-b1f1-4e7f-9052-dc5614100417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting GridSearchCV for LinearSVC (this may take a few minutes)...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "Best params: {'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# --------- 2) Grid search for LinearSVC ----------\n",
    "param_grid = {\"C\": [0.01, 0.1, 1.0, 10.0]}\n",
    "base_svc = LinearSVC(max_iter=10000, tol=1e-4)   # increase max_iter if you get convergence warnings\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=base_svc,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearchCV for LinearSVC (this may take a few minutes)...\")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nBest params:\", grid.best_params_)\n",
    "best_svc = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12abe74a-8d0c-4d9b-99c0-d9e16686cb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 3) Evaluate helper ----------\n",
    "def evaluate_model(model, X, y, split_name=\"VAL\"):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    f1_macro = f1_score(y, y_pred, average=\"macro\")\n",
    "    print(f\"\\n--- {split_name} results ---\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Macro F1:\", f1_macro)\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "482faa9c-e235-4a2d-a9f9-fd14a78a3496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VAL results ---\n",
      "Accuracy: 0.6974418157337949\n",
      "Macro F1: 0.6958566562880777\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      8163\n",
      "           1       0.69      0.66      0.67      7434\n",
      "\n",
      "    accuracy                           0.70     15597\n",
      "   macro avg       0.70      0.70      0.70     15597\n",
      "weighted avg       0.70      0.70      0.70     15597\n",
      "\n",
      "Confusion matrix:\n",
      "[[6002 2161]\n",
      " [2558 4876]]\n",
      "\n",
      "--- TEST results ---\n",
      "Accuracy: 0.7021653792579461\n",
      "Macro F1: 0.7011201631294279\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72      4098\n",
      "           1       0.70      0.67      0.68      3799\n",
      "\n",
      "    accuracy                           0.70      7897\n",
      "   macro avg       0.70      0.70      0.70      7897\n",
      "weighted avg       0.70      0.70      0.70      7897\n",
      "\n",
      "Confusion matrix:\n",
      "[[3006 1092]\n",
      " [1260 2539]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_metrics = evaluate_model(best_svc, X_val_scaled, y_val, split_name=\"VAL\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = evaluate_model(best_svc, X_test_scaled, y_test, split_name=\"TEST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412d5035-d60b-4f93-bb3e-fb7972e0d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model and scaler to inlegalbert_svm_model\n",
      "\n",
      "SUMMARY:\n",
      "Best C: 0.01\n",
      "VAL metrics: {'accuracy': 0.6974418157337949, 'f1_macro': 0.6958566562880777}\n",
      "TEST metrics: {'accuracy': 0.7021653792579461, 'f1_macro': 0.7011201631294279}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --------- 4) Save artifacts ----------\n",
    "out_dir = \"inlegalbert_svm_model\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "joblib.dump(best_svc, os.path.join(out_dir, \"linear_svc_best.joblib\"))\n",
    "joblib.dump(scaler, os.path.join(out_dir, \"scaler.joblib\"))\n",
    "print(f\"\\nSaved model and scaler to {out_dir}\")\n",
    "\n",
    "# --------- 5) Optional: show top-level summary ----------\n",
    "print(\"\\nSUMMARY:\")\n",
    "print(\"Best C:\", grid.best_params_[\"C\"])\n",
    "print(\"VAL metrics:\", val_metrics)\n",
    "print(\"TEST metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5f22098-9269-4e86-9c00-bd59fa7995c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings found in memory.\n",
      "Shapes: (55279, 768) (15597, 768) (7897, 768)\n",
      "Existing saved SVM test macro-F1: 0.7011\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 0) load embeddings & labels if needed ------------------\n",
    "try:\n",
    "    X_train_cls  # noqa\n",
    "    X_val_cls\n",
    "    X_test_cls\n",
    "    print(\"Embeddings found in memory.\")\n",
    "except NameError:\n",
    "    print(\"Loading embeddings from disk...\")\n",
    "    X_train_cls = np.load(\"inlegalbert_cls_embeddings/X_train_cls.npy\")\n",
    "    X_val_cls = np.load(\"inlegalbert_cls_embeddings/X_val_cls.npy\")\n",
    "    X_test_cls = np.load(\"inlegalbert_cls_embeddings/X_test_cls.npy\")\n",
    "\n",
    "y_train = train[\"label\"].to_numpy()\n",
    "y_val = val[\"label\"].to_numpy()\n",
    "y_test = test[\"label\"].to_numpy()\n",
    "\n",
    "print(\"Shapes:\", X_train_cls.shape, X_val_cls.shape, X_test_cls.shape)\n",
    "\n",
    "# ------------------ 1) Prepare scaled versions (for logistic) ------------------\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_cls)\n",
    "X_val_log = scaler_log.transform(X_val_cls)\n",
    "X_test_log = scaler_log.transform(X_test_cls)\n",
    "\n",
    "# Save scaler if needed\n",
    "os.makedirs(\"models_compare\", exist_ok=True)\n",
    "joblib.dump(scaler_log, \"models_compare/scaler_log.joblib\")\n",
    "\n",
    "# ------------------ 2) Load existing SVM test f1 (if available) ------------------\n",
    "best_existing_f1 = None\n",
    "svm_path = \"inlegalbert_svm_model/linear_svc_best.joblib\"\n",
    "if os.path.exists(svm_path):\n",
    "    try:\n",
    "        # We don't have stored metrics file; if you saved them, load; else we can re-evaluate SVM\n",
    "        existing_svc = joblib.load(svm_path)\n",
    "        # Scale test data using saved scaler if exists\n",
    "        scaler_path = \"inlegalbert_svm_model/scaler.joblib\"\n",
    "        if os.path.exists(scaler_path):\n",
    "            existing_scaler = joblib.load(scaler_path)\n",
    "            X_test_for_svm = existing_scaler.transform(X_test_cls)\n",
    "        else:\n",
    "            X_test_for_svm = X_test_log  # fallback\n",
    "        y_pred_svm = existing_svc.predict(X_test_for_svm)\n",
    "        best_existing_f1 = f1_score(y_test, y_pred_svm, average=\"macro\")\n",
    "        print(f\"Existing saved SVM test macro-F1: {best_existing_f1:.4f}\")\n",
    "    except Exception:\n",
    "        best_existing_f1 = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78a35350-4bba-49d3-b74b-a0882a36d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to fit, evaluate and store best model\n",
    "def fit_and_eval(clf, Xtr, ytr, Xval, yval, Xte, yte, searcher, model_name):\n",
    "    t0 = time()\n",
    "    searcher.fit(Xtr, ytr)\n",
    "    elapsed = time() - t0\n",
    "    best = searcher.best_estimator_\n",
    "    print(f\"\\n{model_name} best params: {searcher.best_params_} (fit time: {elapsed:.1f}s)\")\n",
    "    # Evaluate on val & test\n",
    "    yval_pred = best.predict(Xval)\n",
    "    ytest_pred = best.predict(Xte)\n",
    "    val_f1 = f1_score(yval, yval_pred, average=\"macro\")\n",
    "    test_f1 = f1_score(yte, ytest_pred, average=\"macro\")\n",
    "    print(f\"{model_name} VAL macro-F1: {val_f1:.4f} | TEST macro-F1: {test_f1:.4f}\")\n",
    "    print(\"Val classification report:\")\n",
    "    print(classification_report(yval, yval_pred))\n",
    "    print(\"Test classification report:\")\n",
    "    print(classification_report(yte, ytest_pred))\n",
    "    # store\n",
    "    results[model_name] = {\n",
    "        \"best_estimator\": best,\n",
    "        \"best_params\": searcher.best_params_,\n",
    "        \"val_f1\": val_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"fit_time_s\": elapsed\n",
    "    }\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0185459d-4fb2-4677-8bf0-29d0d706d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "from time import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# ------------------ 3) Define models and search grids ------------------\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 3.a Logistic Regression (GridSearch)\n",
    "lr = LogisticRegression(max_iter=2000, solver=\"saga\", random_state=42)\n",
    "lr_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1.0, 10.0],\n",
    "    \"penalty\": [\"l2\"],  # saga supports l1/l2/elasticnet - l2 is robust; add l1 if you want sparsity\n",
    "}\n",
    "\n",
    "# 3.b Random Forest (GridSearch)\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [None, 20, 50],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "\n",
    "# 3.c XGBoost (RandomizedSearch for speed)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except Exception:\n",
    "    xgb_available = False\n",
    "    print(\"xgboost not available; skipping XGBoost. Install with `pip install xgboost` to enable.\")\n",
    "\n",
    "if xgb_available:\n",
    "    xgb = XGBClassifier(objective=\"binary:logistic\", use_label_encoder=False, eval_metric=\"logloss\", tree_method=\"auto\", random_state=42)\n",
    "    xgb_param_dist = {\n",
    "        \"n_estimators\": [100, 200, 400],\n",
    "        \"max_depth\": [3, 6, 10],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"reg_alpha\": [0, 0.1, 1],\n",
    "        \"reg_lambda\": [1, 5, 10],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7020973c-e486-4019-871b-c678cde6f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Tuning Logistic Regression (on scaled embeddings)...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "LogisticRegression best params: {'C': 0.01, 'penalty': 'l2'} (fit time: 1203.8s)\n",
      "LogisticRegression VAL macro-F1: 0.6968 | TEST macro-F1: 0.7024\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      8163\n",
      "           1       0.69      0.66      0.67      7434\n",
      "\n",
      "    accuracy                           0.70     15597\n",
      "   macro avg       0.70      0.70      0.70     15597\n",
      "weighted avg       0.70      0.70      0.70     15597\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      4098\n",
      "           1       0.70      0.67      0.68      3799\n",
      "\n",
      "    accuracy                           0.70      7897\n",
      "   macro avg       0.70      0.70      0.70      7897\n",
      "weighted avg       0.70      0.70      0.70      7897\n",
      "\n",
      "\n",
      ">> Tuning Random Forest (on raw embeddings)...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "RandomForest best params: {'max_depth': 50, 'min_samples_split': 2, 'n_estimators': 500} (fit time: 1526.5s)\n",
      "RandomForest VAL macro-F1: 0.7354 | TEST macro-F1: 0.7361\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77      8163\n",
      "           1       0.78      0.63      0.70      7434\n",
      "\n",
      "    accuracy                           0.74     15597\n",
      "   macro avg       0.75      0.74      0.74     15597\n",
      "weighted avg       0.75      0.74      0.74     15597\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77      4098\n",
      "           1       0.78      0.64      0.70      3799\n",
      "\n",
      "    accuracy                           0.74      7897\n",
      "   macro avg       0.75      0.74      0.74      7897\n",
      "weighted avg       0.75      0.74      0.74      7897\n",
      "\n",
      "\n",
      ">> Tuning XGBoost (on raw embeddings) with RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  35.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  34.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  35.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, reg_lambda=10, subsample=0.8; total time=  31.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, reg_lambda=10, subsample=0.8; total time=  29.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, reg_alpha=1, reg_lambda=10, subsample=0.8; total time=  30.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=  59.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=400, reg_alpha=1, reg_lambda=5, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=0.6; total time=  31.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=0.6; total time=  31.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=10, subsample=0.6; total time=  31.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.6; total time= 1.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=100, reg_alpha=1, reg_lambda=1, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.6; total time= 2.6min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.6; total time= 2.6min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.6; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=10, subsample=0.8; total time= 3.1min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=10, subsample=0.8; total time= 3.2min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=10, subsample=0.8; total time= 3.4min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  17.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=10, subsample=0.6; total time=  15.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=10, subsample=0.6; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=10, subsample=0.6; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=10, subsample=0.6; total time=   8.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 1.7min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 1.7min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=1, subsample=1.0; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  33.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  33.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=0.8; total time=  32.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=1.0; total time= 4.4min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=1.0; total time= 4.1min\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=1.0; total time= 4.2min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=5, subsample=0.8; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=5, subsample=0.8; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0.1, reg_lambda=5, subsample=0.8; total time=  16.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  32.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  33.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=400, reg_alpha=0, reg_lambda=5, subsample=0.6; total time=  32.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1, subsample=0.6; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.8; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.8; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=400, reg_alpha=0.1, reg_lambda=1, subsample=0.8; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=1, reg_lambda=5, subsample=1.0; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time= 2.8min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=400, reg_alpha=0, reg_lambda=1, subsample=0.6; total time= 2.9min\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=100, reg_alpha=1, reg_lambda=5, subsample=0.6; total time=   8.5s\n",
      "\n",
      "XGBoost best params: {'subsample': 0.8, 'reg_lambda': 10, 'reg_alpha': 0, 'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.6} (fit time: 4997.5s)\n",
      "XGBoost VAL macro-F1: 0.7591 | TEST macro-F1: 0.7614\n",
      "Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      8163\n",
      "           1       0.78      0.70      0.74      7434\n",
      "\n",
      "    accuracy                           0.76     15597\n",
      "   macro avg       0.76      0.76      0.76     15597\n",
      "weighted avg       0.76      0.76      0.76     15597\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      4098\n",
      "           1       0.78      0.71      0.74      3799\n",
      "\n",
      "    accuracy                           0.76      7897\n",
      "   macro avg       0.76      0.76      0.76      7897\n",
      "weighted avg       0.76      0.76      0.76      7897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 4) Run GridSearch / RandomizedSearch ------------------\n",
    "# NOTE: adjust cv and n_iter for speed if needed\n",
    "cv_folds = 3\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\n>> Tuning Logistic Regression (on scaled embeddings)...\")\n",
    "lr_search = GridSearchCV(lr, lr_param_grid, scoring=\"f1_macro\", cv=cv_folds, n_jobs=-1, verbose=2)\n",
    "best_lr = fit_and_eval(lr, X_train_log, y_train, X_val_log, y_val, X_test_log, y_test, lr_search, \"LogisticRegression\")\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\n>> Tuning Random Forest (on raw embeddings)...\")\n",
    "rf_search = GridSearchCV(rf, rf_param_grid, scoring=\"f1_macro\", cv=cv_folds, n_jobs=-1, verbose=2)\n",
    "best_rf = fit_and_eval(rf, X_train_cls, y_train, X_val_cls, y_val, X_test_cls, y_test, rf_search, \"RandomForest\")\n",
    "\n",
    "# XGBoost (if available) - use RandomizedSearchCV for speed\n",
    "best_xgb = None\n",
    "if xgb_available:\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    print(\"\\n>> Tuning XGBoost (on raw embeddings) with RandomizedSearchCV...\")\n",
    "    xgb_search = RandomizedSearchCV(xgb, xgb_param_dist, n_iter=20, scoring=\"f1_macro\", cv=cv_folds, n_jobs=1, verbose=2, random_state=42)\n",
    "    best_xgb = fit_and_eval(xgb, X_train_cls, y_train, X_val_cls, y_val, X_test_cls, y_test, xgb_search, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3c464ab-0e42-40b9-9f9d-fc92c170afca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST results ---\n",
      "Accuracy: 0.7021653792579461\n",
      "Macro F1: 0.7011201631294279\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72      4098\n",
      "           1       0.70      0.67      0.68      3799\n",
      "\n",
      "    accuracy                           0.70      7897\n",
      "   macro avg       0.70      0.70      0.70      7897\n",
      "weighted avg       0.70      0.70      0.70      7897\n",
      "\n",
      "Confusion matrix:\n",
      "[[3006 1092]\n",
      " [1260 2539]]\n",
      "\n",
      "Added LinearSVM to results dict.\n",
      "{'best_estimator': LinearSVC(C=0.01, max_iter=10000), 'best_params': {'C': 0.01}, 'val_f1': 0.6958566562880777, 'test_f1': 0.7011201631294279, 'fit_time_s': np.float64(96.30051652590434)}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_svc, X_test_scaled, y_test, split_name=\"TEST\")\n",
    "# --------- 6) Add SVM results to global results dict ----------\n",
    "model_name = \"LinearSVM\"\n",
    "\n",
    "results[model_name] = {\n",
    "    \"best_estimator\": best_svc,\n",
    "    \"best_params\": grid.best_params_,\n",
    "    \"val_f1\": val_metrics[\"f1_macro\"],\n",
    "    \"test_f1\": test_metrics[\"f1_macro\"],\n",
    "    \"fit_time_s\": grid.cv_results_[\"mean_fit_time\"][grid.best_index_]\n",
    "}\n",
    "\n",
    "print(\"\\nAdded LinearSVM to results dict.\")\n",
    "print(results[model_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7997d63-372f-4b63-875c-c87974c14324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VotingClassifier using ALL models...\n",
      "Ensemble TEST macro-F1: 0.7305721555926556\n",
      "Saved ensemble to models_compare/voting_ensemble_hard.joblib\n",
      "\n",
      "Done. Ensemble built using all models in results.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# ------------------ NEW ENSEMBLE (works for all models) ------------------\n",
    "\n",
    "ensemble_estimators = []\n",
    "\n",
    "for model_name, info in results.items():\n",
    "    est = info[\"best_estimator\"]\n",
    "    \n",
    "    # If model was trained on scaled embeddings\n",
    "    if \"scaler\" in info:\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", info[\"scaler\"]),\n",
    "            (\"clf\", est)\n",
    "        ])\n",
    "        ensemble_estimators.append((model_name, pipe))\n",
    "    else:\n",
    "        # raw-embedding models (e.g., RandomForest, XGBoost)\n",
    "        ensemble_estimators.append((model_name, est))\n",
    "\n",
    "\n",
    "if len(ensemble_estimators) >= 2:\n",
    "    # build ensemble with all models\n",
    "    voting = VotingClassifier(\n",
    "        estimators=ensemble_estimators,\n",
    "        voting=\"hard\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining VotingClassifier using ALL models...\")\n",
    "    voting.fit(X_train_cls, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = voting.predict(X_test_cls)\n",
    "    ensemble_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(\"Ensemble TEST macro-F1:\", ensemble_f1)\n",
    "\n",
    "    # Save\n",
    "    joblib.dump(voting, \"models_compare/voting_ensemble_hard.joblib\")\n",
    "    print(\"Saved ensemble to models_compare/voting_ensemble_hard.joblib\")\n",
    "\n",
    "print(\"\\nDone. Ensemble built using all models in results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c2e6726-13d2-4f56-a4bf-22030b9512fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results_dict.joblib ✅\n",
      "Saved train/test embeddings and labels ✅\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(results, \"models_compare/results_dict.joblib\")\n",
    "print(\"Saved results_dict.joblib ✅\")\n",
    "joblib.dump(X_train_cls, \"models_compare/X_train_cls.joblib\")\n",
    "joblib.dump(y_train, \"models_compare/y_train.joblib\")\n",
    "joblib.dump(X_test_cls, \"models_compare/X_test_cls.joblib\")\n",
    "joblib.dump(y_test, \"models_compare/y_test.joblib\")\n",
    "\n",
    "print(\"Saved train/test embeddings and labels ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d9a6d6c-5be9-43ba-823e-4b361ba68041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base estimators for stacking: ['LogisticRegression', 'RandomForest', 'XGBoost', 'LinearSVM']\n",
      "\n",
      "Generating OOF predictions...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "OOF matrix shape: (55279, 8)\n",
      "Test stacked matrix shape: (7897, 8)\n",
      "\n",
      "=== STACKING RESULTS ===\n",
      "Stacking Test Macro F1: 0.7619124776815973\n",
      "Saved stack_base_models.joblib and stack_meta_clf.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# =========================================================\n",
    "# 1. Build final estimators list with correct scaling\n",
    "# =========================================================\n",
    "\n",
    "stack_estimators = []\n",
    "\n",
    "for model_name, info in results.items():\n",
    "    est = info[\"best_estimator\"]\n",
    "    \n",
    "    # wrap model in pipeline if it used a scaler\n",
    "    if \"scaler\" in info and info[\"scaler\"] is not None:\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", info[\"scaler\"]),\n",
    "            (\"clf\", est)\n",
    "        ])\n",
    "        stack_estimators.append((model_name, pipe))\n",
    "    else:\n",
    "        stack_estimators.append((model_name, est))\n",
    "\n",
    "print(\"\\nBase estimators for stacking:\", [name for name, _ in stack_estimators])\n",
    "\n",
    "# =========================================================\n",
    "# 2. Out-of-fold prediction matrix for stacking\n",
    "# =========================================================\n",
    "\n",
    "n_models = len(stack_estimators)\n",
    "n_train = X_train_cls.shape[0]\n",
    "n_test = X_test_cls.shape[0]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# OOF predictions: (n_samples, n_models * n_classes)\n",
    "oof_train = np.zeros((n_train, n_models * n_classes))\n",
    "test_pred_accumulator = np.zeros((n_test, n_models * n_classes))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\nGenerating OOF predictions...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_cls, y_train)):\n",
    "    print(f\"  Fold {fold+1}/5\")\n",
    "    \n",
    "    X_tr, X_val = X_train_cls[train_idx], X_train_cls[val_idx]\n",
    "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "    col = 0\n",
    "    for name, model in stack_estimators:\n",
    "\n",
    "        cloned_model = clone(model)\n",
    "        cloned_model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # -------- Unified prediction function --------\n",
    "        def get_proba(m, X):\n",
    "            if hasattr(m, \"predict_proba\"):\n",
    "                return m.predict_proba(X)\n",
    "            elif hasattr(m, \"decision_function\"):\n",
    "                df = m.decision_function(X)\n",
    "                # Handle binary classifiers\n",
    "                if df.ndim == 1:\n",
    "                    df = np.vstack([-df, df]).T\n",
    "                exp = np.exp(df - df.max(axis=1, keepdims=True))\n",
    "                return exp / exp.sum(axis=1, keepdims=True)\n",
    "            else:\n",
    "                preds = m.predict(X)\n",
    "                oh = np.zeros((len(preds), n_classes))\n",
    "                oh[np.arange(len(preds)), preds] = 1\n",
    "                return oh\n",
    "\n",
    "        # OOF validation predictions\n",
    "        val_proba = get_proba(cloned_model, X_val)\n",
    "        oof_train[val_idx, col:col+n_classes] = val_proba\n",
    "        \n",
    "        # Test predictions\n",
    "        test_proba = get_proba(cloned_model, X_test_cls)\n",
    "        test_pred_accumulator[:, col:col+n_classes] += test_proba\n",
    "        \n",
    "        col += n_classes\n",
    "\n",
    "# average test predictions\n",
    "oof_test = test_pred_accumulator / skf.n_splits\n",
    "\n",
    "print(\"OOF matrix shape:\", oof_train.shape)\n",
    "print(\"Test stacked matrix shape:\", oof_test.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 3. Train meta-model on OOF predictions\n",
    "# =========================================================\n",
    "\n",
    "meta_clf = LogisticRegression(max_iter=5000)\n",
    "meta_clf.fit(oof_train, y_train)\n",
    "\n",
    "# evaluate performance\n",
    "y_test_pred = meta_clf.predict(oof_test)\n",
    "stack_test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "print(\"\\n=== STACKING RESULTS ===\")\n",
    "print(\"Stacking Test Macro F1:\", stack_test_f1)\n",
    "\n",
    "# =========================================================\n",
    "# 4. Save stacking components\n",
    "# =========================================================\n",
    "\n",
    "joblib.dump(stack_estimators, \"models_compare/stack_base_models.joblib\")\n",
    "joblib.dump(meta_clf, \"models_compare/stack_meta_clf.joblib\")\n",
    "\n",
    "print(\"Saved stack_base_models.joblib and stack_meta_clf.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4183bf54-b985-4708-99a4-c167570d8f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacking Classifier Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      4098\n",
      "           1       0.77      0.72      0.74      3799\n",
      "\n",
      "    accuracy                           0.76      7897\n",
      "   macro avg       0.76      0.76      0.76      7897\n",
      "weighted avg       0.76      0.76      0.76      7897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Stacking Model Report\n",
    "# -----------------------------\n",
    "print(\"=== Stacking Classifier Report ===\")\n",
    "stack_report = classification_report(y_test, y_test_pred)\n",
    "print(stack_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d699e2fc-c27c-4bb6-b8d3-d8539fb5e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Voting Classifier Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      4098\n",
      "           1       0.79      0.61      0.69      3799\n",
      "\n",
      "    accuracy                           0.74      7897\n",
      "   macro avg       0.75      0.73      0.73      7897\n",
      "weighted avg       0.75      0.74      0.73      7897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Voting Classifier Report ===\")\n",
    "voting_report = classification_report(y_test, y_pred)\n",
    "print(voting_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822e6e5-fe05-430f-8e0b-85978c75a4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
